#!/usr/bin/python3

import argparse
import json
import sys
import os
import requests
from bs4 import BeautifulSoup
import re
from pathlib import Path


class bcolors:
    HEADER = "\033[95m"
    OKBLUE = "\033[94m"
    OKCYAN = "\033[96m"
    OKGREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"
    UNDERLINE = "\033[4m"


class Argparser(object):
    def __init__(self):
        parser = argparse.ArgumentParser()
        parser.add_argument("--url", type=str, nargs="+", help="url to scrape")
        parser.add_argument(
            "--name", type=str, nargs="+", help="url to scrape"
        )
        parser.add_argument(
            "--dbg", action="store_true", help="debug", default=False
        )
        parser.add_argument(
            "--demon", action="store_true", help="run as daemon", default=False
        )
        parser.add_argument(
            "--manga",
            action="store_true",
            help="run manga scraper",
            default=False,
        )
        parser.add_argument(
            "--anime",
            action="store_true",
            help="run anime scraper",
            default=False,
        )
        parser.add_argument(
            "--cb", action="store_true", help="run cb scraper", default=False
        )
        parser.add_argument(
            "--slumber", type=int, help="how long the demon sleeps", default=60
        )
        self.args = parser.parse_args()


path = str()
if Path(sys.argv[0]).is_symlink():
    path = os.readlink(sys.argv[0])
else:
    path = sys.argv[0]


def mrg(url):
    requests.packages.urllib3.disable_warnings()
    resp = requests.get(url, verify=False)
    soup = BeautifulSoup(resp.text, "lxml")
    search = soup.find_all("div", class_="label")

    Up_Time = str()
    for elem in search:
        if elem.string == "Last Broadcast:":
            Up_Time = elem.next_sibling.next_sibling.string
            # print(elem.next_sibling.next_sibling)

    if Up_Time.find("minutes") != -1:
        return True
    else:
        return False


def run_cb_scrape():
    url = json.load(open(os.path_dirname(path) + "/cb.json"))
    if mrg(url["1"]):
        print("mg ", end="")
        vocalize(os.path.expanduser("~") + "/scripts/mila/mgup.ogg")
    if mrg(url["2"]):
        print("obk ", end="")
        vocalize(os.path.expanduser("~") + "/scripts/mila/obkup.ogg")
    if mrg(url["5"]):
        print("ls ", end="")
        vocalize(os.path.expanduser("~") + "/scripts/mila/lisaup.ogg")


def manga_scrape():
    urls = json.load(open(os.path.dirname(path) + "/manga.json"))
    requests.packages.urllib3.disable_warnings()
    result = str()
    for name, url in urls.items():
        resp = requests.get(url, verify=False, allow_redirects=True)
        soup = BeautifulSoup(resp.text, "lxml")
        search = soup.find_all("a", class_="chapter-name text-nowrap")
        re_res = []
        for thing in search:
            # re_res.append(re.findall("Chapter [0-9]*[.[0-9]*]?", thing.text))
            re_res.append(
                bcolors.OKGREEN
                + thing["title"]
                + " >>> "
                + bcolors.OKCYAN
                + thing["href"]
            )
        try:
            # result += name + "-->" + re_res[0][0] + "\n"
            # result += bcolors.OKBLUE + name + "-->" + re_res[0] + "\n"
            result += re_res[0] + "\n"
        except IndexError:
            result += name + "--> nothing\n"
    print(result, end="")


def anime_scrape():
    urls = json.load(open(os.path.dirname(path) + "/anime.json"))
    requests.packages.urllib3.disable_warnings()
    result = str()
    for name, url in urls.items():
        resp = requests.get(url, verify=False)
        soup = BeautifulSoup(resp.text, "lxml")
        search = soup.find_all("a", href=True)
        re_res = []
        for thing in search:
            re_res.append(re.findall("Episode [0-9]*$", thing.text))
        # print(name+":"+repr(max(re_res)))
        result += name + ":" + repr(max(re_res)) + "\n"
    print(result, end="")


def vocalize(sound):
    # import subprocess
    # subprocess.call([os.path.expanduser("~") + "/scripts/voice.sh", sound])
    pass


def main():
    argparser = Argparser()
    if argparser.args.cb:
        run_cb_scrape()
    elif argparser.args.manga:
        manga_scrape()
    elif argparser.args.anime:
        anime_scrape()
    else:
        pass


if __name__ == "__main__":
    main()
